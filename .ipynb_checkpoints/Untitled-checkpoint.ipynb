{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd12f05c-f585-4217-990e-0e5d918d6861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Install packages (run if packages missing)\n",
    "# If running on Colab or fresh environment, uncomment the pip installs below.\n",
    "\n",
    "# !pip install --upgrade pip\n",
    "# !pip install pillow matplotlib numpy pandas scikit-learn tensorflow tensorflow-addons\n",
    "\n",
    "# If already installed, you can skip installs.\n",
    "\n",
    "import importlib, sys\n",
    "print(\"Python\", sys.version.splitlines()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c9f571e-a4fd-4c6b-90dd-85bea67ed002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\saaar\\AppData\\Local\\Temp\\ipykernel_22600\\1232613623.py\", line 7, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py\", line 159, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 28, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py\", line 144, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\saaar\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.2.6 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageDraw, ImageFilter, ImageEnhance, ImageOps\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:159\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py:144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    146\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    148\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    149\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    157\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "# Cell 3: imports\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageEnhance, ImageOps\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support\n",
    "import tensorflow_addons as tfa  # optional, used only if you enable focal loss\n",
    "\n",
    "print(\"TensorFlow\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78dc3a-341c-4456-b12f-f40c66445cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: parameters and reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "DATA_DIR = \"data\"       # where dataset will live\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "EPOCHS = 10           # shorter for quick demo; increase for real training\n",
    "FINE_TUNE_EPOCHS = 5\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "BACKBONE = 'EfficientNetB0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4038cfe-cb7e-4b99-8ca0-7fd029d16de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: utility functions (image ops, plotting, overlay, CLAHE alternative)\n",
    "from typing import Tuple\n",
    "\n",
    "def pil_open(path):\n",
    "    return Image.open(path).convert(\"RGB\")\n",
    "\n",
    "def resize_pil(img: Image.Image, size: Tuple[int,int]):\n",
    "    return img.resize(size, Image.BILINEAR)\n",
    "\n",
    "def show_img(img, title=None):\n",
    "    plt.imshow(np.asarray(img).astype('uint8'))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "def plot_grid(imgs, titles=None, cols=4, size=(3,3)):\n",
    "    n = len(imgs)\n",
    "    rows = (n + cols - 1) // cols\n",
    "    plt.figure(figsize=(size[0]*cols, size[1]*rows))\n",
    "    for i, im in enumerate(imgs):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        show_img(im, None if not titles else titles[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Simple global equalization using PIL (not CLAHE but helps contrast)\n",
    "def equalize_pil(img: Image.Image) -> Image.Image:\n",
    "    return ImageOps.equalize(img)\n",
    "\n",
    "# Create a heatmap overlay without cv2 using matplotlib colormap and PIL blending\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def overlay_heatmap_pil(image: Image.Image, heatmap: np.ndarray, alpha=0.4):\n",
    "    \"\"\"\n",
    "    image: PIL RGB image\n",
    "    heatmap: 2D numpy array with values in [0,1]\n",
    "    \"\"\"\n",
    "    h, w = image.size[1], image.size[0]\n",
    "    # Normalize and map to colormap\n",
    "    heat_norm = np.clip(heatmap, 0.0, 1.0)\n",
    "    cmap = cm.get_cmap(\"jet\")\n",
    "    heat_rgba = cmap(heat_norm)[:, :, :3]  # HxWx3 floats\n",
    "    # Convert heatmap to PIL Image\n",
    "    heat_img = Image.fromarray((heat_rgba * 255).astype('uint8')).resize((w,h), resample=Image.BILINEAR)\n",
    "    # Blend\n",
    "    blended = Image.blend(image, heat_img, alpha=alpha)\n",
    "    return blended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e81d6e-0eaa-4c1e-8974-3cb9aa74e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: generate synthetic dataset\n",
    "def draw_rbc(draw, center, radius, fill=(220,180,180), outline=(120,60,60)):\n",
    "    x,y = center\n",
    "    bbox = [x-radius, y-radius, x+radius, y+radius]\n",
    "    draw.ellipse(bbox, fill=fill, outline=outline)\n",
    "\n",
    "def add_parasite(draw, center, radius, color=(180,0,0)):\n",
    "    x,y = center\n",
    "    # small offset inside the RBC\n",
    "    dx = random.randint(-radius//3, radius//3)\n",
    "    dy = random.randint(-radius//3, radius//3)\n",
    "    r = max(2, radius//6)\n",
    "    draw.ellipse([x+dx-r, y+dy-r, x+dx+r, y+dy+r], fill=color)\n",
    "\n",
    "def make_image(img_size=(224,224), infected=False):\n",
    "    W, H = img_size\n",
    "    img = Image.new(\"RGB\", (W,H), (245,245,245))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    # RBC center roughly center with jitter\n",
    "    cx = W//2 + random.randint(-10,10)\n",
    "    cy = H//2 + random.randint(-10,10)\n",
    "    radius = min(W,H)//3 + random.randint(-8,8)\n",
    "    # Randomize cell color a bit\n",
    "    base = (random.randint(200,235), random.randint(160,200), random.randint(160,200))\n",
    "    draw_rbc(draw, (cx,cy), radius, fill=base, outline=(120,80,90))\n",
    "    # Add small artifacts / noise\n",
    "    if random.random() < 0.3:\n",
    "        # light dot\n",
    "        dx = random.randint(10,W-10)\n",
    "        dy = random.randint(10,H-10)\n",
    "        draw.ellipse([dx-2,dy-2,dx+2,dy+2], fill=(200,200,200))\n",
    "    if infected:\n",
    "        add_parasite(draw, (cx,cy), radius, color=(180,0,0))\n",
    "    # Slight blur to mimic microscope\n",
    "    img = img.filter(ImageFilter.GaussianBlur(radius=0.7))\n",
    "    # Slight contrast adjust\n",
    "    img = ImageEnhance.Contrast(img).enhance(1.05)\n",
    "    return img\n",
    "\n",
    "def generate_dataset(root=\"data_synthetic\", n_per_class=200, img_size=IMG_SIZE):\n",
    "    root = Path(root)\n",
    "    for split in (\"train\",\"val\",\"test\"):\n",
    "        for cls in (\"healthy\",\"infected\"):\n",
    "            dirp = root / split / cls\n",
    "            dirp.mkdir(parents=True, exist_ok=True)\n",
    "    # ratios for splits\n",
    "    for cls, infected in [(\"healthy\", False), (\"infected\", True)]:\n",
    "        for i in range(n_per_class):\n",
    "            img = make_image(img_size=img_size, infected=infected)\n",
    "            # decide split\n",
    "            r = random.random()\n",
    "            if r < 0.7:\n",
    "                split = \"train\"\n",
    "            elif r < 0.85:\n",
    "                split = \"val\"\n",
    "            else:\n",
    "                split = \"test\"\n",
    "            # name & save\n",
    "            outdir = Path(\"data_synthetic\") / split / cls\n",
    "            outpath = outdir / f\"{cls}_{i:04d}.png\"\n",
    "            img.save(outpath)\n",
    "    return Path(\"data_synthetic\")\n",
    "\n",
    "# generate small dataset\n",
    "synthetic_root = generate_dataset(root=\"data_synthetic\", n_per_class=300)\n",
    "print(\"Synthetic dataset created at:\", synthetic_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cf9823-ea57-478f-b94e-7e25f1db8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: set data dir to synthetic dataset for now\n",
    "DATA_DIR = \"data_synthetic\"   # change to your dataset path when available\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_DIR   = os.path.join(DATA_DIR, \"val\")\n",
    "TEST_DIR  = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "print(\"Train dir exists:\", os.path.exists(TRAIN_DIR))\n",
    "print(\"Val dir exists:\", os.path.exists(VAL_DIR))\n",
    "print(\"Test dir exists:\", os.path.exists(TEST_DIR))\n",
    "\n",
    "# use image_dataset_from_directory\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TRAIN_DIR, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary', seed=SEED, shuffle=True\n",
    ")\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    VAL_DIR, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary', shuffle=False\n",
    ")\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    TEST_DIR, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='binary', shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b8b87-2bdb-4c7a-afd9-833443d78d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: show some samples and class counts\n",
    "# display some images\n",
    "sample_paths = []\n",
    "for cls in class_names:\n",
    "    p = next(Path(TRAIN_DIR).joinpath(cls).glob('*'))\n",
    "    sample_paths.append(p)\n",
    "imgs = [resize_pil(Image.open(p).convert(\"RGB\"), IMG_SIZE) for p in sample_paths]\n",
    "plot_grid(imgs, titles=class_names, cols=len(imgs), size=(3,3))\n",
    "\n",
    "# class counts\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "for imgs, labels in train_ds.unbatch():\n",
    "    counter[int(labels.numpy())] += 1\n",
    "print(\"Train distribution:\", counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7170f47-84ea-4f8c-824b-da5367bd0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: augmentation and preprocess\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal_and_vertical'),\n",
    "    layers.RandomRotation(0.12),\n",
    "    layers.RandomZoom(0.12),\n",
    "    layers.RandomTranslation(0.06, 0.06),\n",
    "    layers.RandomContrast(0.08)\n",
    "], name='data_augmentation')\n",
    "\n",
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b3493-71ff-447f-9ee0-6791a7b85ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: model builder\n",
    "def build_model(img_size=IMG_SIZE, backbone='EfficientNetB0', dropout=0.3, lr=1e-3):\n",
    "    if backbone == 'EfficientNetB0':\n",
    "        base = tf.keras.applications.EfficientNetB0(include_top=False, weights='imagenet', input_shape=(*img_size,3))\n",
    "    else:\n",
    "        base = tf.keras.applications.MobileNetV2(include_top=False, weights='imagenet', input_shape=(*img_size,3))\n",
    "    base.trainable = False\n",
    "\n",
    "    inputs = keras.Input(shape=(*img_size,3))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', keras.metrics.AUC(name='auc')])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38920a7d-9a8b-4a34-8da4-e33d0c92e65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: callbacks and class weights\n",
    "logdir = os.path.join(OUTPUT_DIR, \"logs\")\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(os.path.join(OUTPUT_DIR, \"best_model.h5\"), save_best_only=True, monitor='val_auc', mode='max'),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, mode='max', min_lr=1e-7),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_auc', patience=6, mode='max', restore_best_weights=True),\n",
    "    keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "]\n",
    "\n",
    "# compute class weights\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "for imgs, labels in train_ds.unbatch():\n",
    "    counter[int(labels.numpy())] += 1\n",
    "total = sum(counter.values())\n",
    "class_weights = {i: total/(len(counter)*count) for i,count in counter.items()}\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e6069e-8e8f-429c-b0f9-70cf0c5bc040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20: train\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights\n",
    ")\n",
    "# plot training curves\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='train_loss'); plt.plot(history.history['val_loss'], label='val_loss'); plt.legend(); plt.title('Loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='train_acc'); plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "if 'auc' in history.history:\n",
    "    plt.plot(history.history['auc'], label='train_auc'); plt.plot(history.history['val_auc'], label='val_auc')\n",
    "plt.legend(); plt.title('Metrics')\n",
    "plt.show()\n",
    "\n",
    "model.save(os.path.join(OUTPUT_DIR, \"model_initial.h5\"))\n",
    "print(\"Saved model_initial.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb611e3c-5498-4131-aeff-245b69874c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22: fine-tune\n",
    "# find and unfreeze top layers of base\n",
    "base_model = None\n",
    "for layer in model.layers:\n",
    "    if isinstance(layer, tf.keras.Model) and 'efficientnet' in layer.name:\n",
    "        base_model = layer\n",
    "        break\n",
    "if base_model is None:\n",
    "    # fallback: find first layer with many sublayers\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'layers') and len(getattr(layer, 'layers'))>20:\n",
    "            base_model = layer\n",
    "            break\n",
    "print(\"Base model identified:\", getattr(base_model, 'name', 'unknown'))\n",
    "\n",
    "base_model.trainable = True\n",
    "fine_tune_at = int(len(base_model.layers) * 0.6)\n",
    "for l in base_model.layers[:fine_tune_at]:\n",
    "    l.trainable = False\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', keras.metrics.AUC(name='auc')])\n",
    "\n",
    "history_ft = model.fit(train_ds, validation_data=val_ds, epochs=FINE_TUNE_EPOCHS, callbacks=callbacks, class_weight=class_weights)\n",
    "plt.plot(history_ft.history.get('val_auc', [])); plt.title('Fine-tune val_auc'); plt.show()\n",
    "\n",
    "model.save(os.path.join(OUTPUT_DIR, \"model_finetuned.h5\"))\n",
    "print(\"Saved model_finetuned.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0b0196-af5c-480d-af6c-9b5889a2eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Cell 24: evaluation\n",
    "y_true = []\n",
    "y_prob = []\n",
    "for imgs, labels in test_ds:\n",
    "    preds = model.predict(imgs)\n",
    "    y_true.extend(labels.numpy().astype(int).tolist())\n",
    "    y_prob.extend(preds.ravel().tolist())\n",
    "\n",
    "y_pred = [1 if p >= 0.5 else 0 for p in y_prob]\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(cm, cmap='Blues'); plt.colorbar()\n",
    "plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "plt.yticks(range(len(class_names)), class_names)\n",
    "plt.xlabel('Predicted'); plt.ylabel('True'); plt.title('Confusion Matrix'); plt.show()\n",
    "\n",
    "auc = roc_auc_score(y_true, y_prob)\n",
    "print(\"ROC AUC:\", auc)\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=[0,1])\n",
    "print(\"Precision (classwise):\", precision)\n",
    "print(\"Recall (classwise; sensitivity):\", recall)\n",
    "print(\"F1 (classwise):\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b828a2-a223-4c90-87ce-d322673dd449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_last_conv_layer(model):\n",
    "    # fallback automatic detection\n",
    "    for layer in reversed(model.layers):\n",
    "        if hasattr(layer, \"output_shape\") and len(layer.output_shape) == 4:\n",
    "            return layer.name\n",
    "    return None\n",
    "\n",
    "# Force correct layer for EfficientNet\n",
    "try:\n",
    "    last_conv = model.get_layer(\"top_conv\").name\n",
    "except:\n",
    "    last_conv = find_last_conv_layer(model)\n",
    "\n",
    "print(\"Using last conv layer:\", last_conv)\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "\n",
    "    # Build a model that maps input â†’ activations + predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=[last_conv_layer.output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]\n",
    "\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap).numpy()\n",
    "\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    if heatmap.max() != 0:\n",
    "        heatmap /= heatmap.max()\n",
    "    else:\n",
    "        heatmap = np.zeros_like(heatmap)\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0062df-4b85-4ce5-b414-cee26ffaa138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 28: TF-Lite conversion\n",
    "try:\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_model = converter.convert()\n",
    "    tflite_path = os.path.join(OUTPUT_DIR, \"malaria_model_dynamic.tflite\")\n",
    "    with open(tflite_path, \"wb\") as f:\n",
    "        f.write(tflite_model)\n",
    "    print(\"Saved TF-Lite model to\", tflite_path)\n",
    "except Exception as e:\n",
    "    print(\"TF-Lite conversion failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ad280-81ff-4671-8439-10838e5d6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 30: write flask_example.py\n",
    "flask_code = r\"\"\"\n",
    "from flask import Flask, request, jsonify\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import tensorflow as tf\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = tf.keras.models.load_model('outputs/model_finetuned.h5')\n",
    "\n",
    "def preprocess_image_bytes(img_bytes):\n",
    "    img = Image.open(io.BytesIO(img_bytes)).convert('RGB').resize((224,224))\n",
    "    arr = np.array(img).astype('float32')\n",
    "    arr = tf.keras.applications.efficientnet.preprocess_input(arr)\n",
    "    return np.expand_dims(arr, axis=0)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    file = request.files.get('image')\n",
    "    if file is None:\n",
    "        return jsonify({'error': 'no image received'}), 400\n",
    "    img = preprocess_image_bytes(file.read())\n",
    "    prob = float(model.predict(img)[0,0])\n",
    "    label = 'infected' if prob >= 0.5 else 'healthy'\n",
    "    return jsonify({'label': label, 'probability': prob})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "\"\"\"\n",
    "open(os.path.join(OUTPUT_DIR, \"flask_example.py\"), \"w\").write(flask_code)\n",
    "print(\"Wrote outputs/flask_example.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e1a3e-0cd6-418d-bfd9-040cfde41f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a699c21-dcb4-4736-9420-d7333ce3e139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd291d-4f69-4be0-b6c3-f1d8b15401fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
